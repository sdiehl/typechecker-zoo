# Bidirectional Type Checking

The type inference engine represents the most  component of our System Fω implementation. Built around the DK (Dunfield-Krishnaswami) worklist algorithm, it handles the complex interactions between higher-rank polymorphism, existential type variables, and bidirectional type checking that make System Fω both powerful and challenging to implement efficiently.

The algorithm operates on a **worklist** of judgments and constraints, systematically reducing complex type checking problems into simpler ones until all constraints are resolved. This approach provides decidable type inference for System Fω while maintaining principal types and supporting polymorphic programming patterns.

Notably this approach is different from the direct tree-walking approach we used before. Now we walk the syntax tree and emit constraints, which are then solved by the worklist algorithm, and then back-propagate the results to the original syntax tree to give the final types. This system allows more complex rules to be introduced, but it also makes the entire process "non-local" in the sense that we are looking at a constraint generated by many different expressions, and thus error reporting becomes a bit more challenging because tracing back a constraint problem to its original syntax requires quite a bit of bookkeeping

## Typing Rules

Now we're going to bodly go into the next generation of type checking. We have some new symbols in our type system, but they're mostly the same as before except for the addition of new kind-level operations.

* **\\( \\Gamma \\) (Gamma)** - The typing context that stores information about variables and their types.

* **\\( \\vdash \\) (Turnstile)** - The "proves" relation, meaning "given this context, we can conclude this judgment."

* **\\( \\Rightarrow \\) (Double Right Arrow)** - Synthesis mode, where the type checker figures out what type an expression has.

* **\\( \\Leftarrow \\) (Double Left Arrow)** - Checking mode, where we verify that an expression has the expected type.

* **\\( \\forall\\alpha \\) (Forall Alpha)** - Universal quantification, meaning "for any type α."

* **\\( :: \\) (Double Colon)** - The "has kind" relation, telling us what category a type constructor belongs to.

* **\\( \\star \\) (Star)** - The kind of concrete types like `Int`, `Bool`, and `String`.

* **\\( \\square \\) (Box)** - The kind of kinds, the kind that kinds themselves have.

* **\\( \\to \\) (Arrow)** - Function types at the term level, or kind arrows at the type level.

* **\\( [B/\\alpha]A \\)** - Type substitution that replaces all occurrences of type variable α with type B in type A.

* **\\( \\Lambda\\alpha \\) (Big Lambda)** - Type abstraction that creates polymorphic functions at the type level.

* **\\( \\kappa \\) (Kappa)** - Kind variables representing unknown categories in our type system.

* **\\( \\overline{x} \\)** - Overline notation indicating a sequence or list of elements, such as multiple variables or arguments.

Before examining the DK worklist algorithm implementation, let's establish the formal typing rules that govern System Fω. These rules extend System F with higher-kinded types and more  polymorphism.

### Basic Expression Rules

Variable lookup finds types in the context:

\\[ \frac{x : A \in \Gamma}{\Gamma \vdash x \Rightarrow A} \text{(T-Var)} \\]

Function application with bidirectional checking:

\\[ \frac{\Gamma \vdash e_1 \Rightarrow A \to B \quad \Gamma \vdash e_2 \Leftarrow A}{\Gamma \vdash e_1 \; e_2 \Rightarrow B} \text{(T-App)} \\]

Lambda abstraction in checking mode:

\\[ \frac{\Gamma, x : A \vdash e \Leftarrow B}{\Gamma \vdash \lambda x. e \Leftarrow A \to B} \text{(T-Lam)} \\]

### Type Application and Abstraction

Type application instantiates polymorphic expressions:

\\[ \frac{\Gamma \vdash e \Rightarrow \forall \alpha :: \kappa. A \quad \Gamma \vdash B :: \kappa}{\Gamma \vdash e \; [B] \Rightarrow [B/\alpha]A} \text{(T-TApp)} \\]

Type abstraction introduces universal quantification:

\\[ \frac{\Gamma, \alpha :: \kappa \vdash e \Leftarrow A}{\Gamma \vdash \Lambda \alpha :: \kappa. e \Leftarrow \forall \alpha :: \kappa. A} \text{(T-TAbs)} \\]

### Higher-Kinded Type Rules

Kind checking ensures type constructors are well-formed:

\\[ \frac{}{\Gamma \vdash \star :: \square} \text{(K-Type)} \\]

\\[ \frac{\Gamma \vdash \kappa_1 :: \square \quad \Gamma \vdash \kappa_2 :: \square}{\Gamma \vdash \kappa_1 \to \kappa_2 :: \square} \text{(K-Arrow)} \\]

Type constructor application:

\\[ \frac{\Gamma \vdash F :: \kappa_1 \to \kappa_2 \quad \Gamma \vdash A :: \kappa_1}{\Gamma \vdash F \; A :: \kappa_2} \text{(K-App)} \\]

### Pattern Matching Rules

Constructor patterns check against data types:

\\[ \frac{\Gamma \vdash e \Rightarrow T \quad \overline{\Gamma \vdash p_i \Leftarrow T \leadsto \Delta_i \quad \Gamma, \Delta_i \vdash e_i \Leftarrow A}}{\Gamma \vdash \text{match } e \text{ with } \overline{p_i \to e_i} \Rightarrow A} \text{(T-Match)} \\]

### Bidirectional Control

Mode switching from inference to checking:

\\[ \frac{\Gamma \vdash e \Rightarrow A}{\Gamma \vdash e \Leftarrow A} \text{(T-Sub)} \\]

Existential variable instantiation:

\\[ \frac{\Gamma, \hat{\alpha} :: \kappa \vdash e \Rightarrow A}{\Gamma \vdash e \Rightarrow [\hat{\alpha}/\alpha]A} \text{(T-InstL)} \\]

In these rules, \\( \Rightarrow \\) denotes **inference** mode (synthesizing types), \\( \Leftarrow \\) denotes **checking** mode (verifying against expected types), \\( :: \\) relates types to their kinds, and \\( \hat{\alpha} \\) represents existential type variables solved during inference.

## The DK Worklist Algorithm

The DK algorithm represents type inference as a constraint solving problem. Instead of recursively traversing expressions and immediately making type checking decisions, it accumulates constraints in a worklist and processes them systematically.

### Worklist Structure

```rust
#![enum!("system-f-omega/src/worklist.rs", WorklistEntry)]
```

The worklist contains three fundamental kinds of entries that work together to manage the type checking process. Type variable bindings track type variables and their current status, which can be universal (from explicit quantifiers), existential (representing unknown types that need inference), or solved (existential variables that have been determined through constraint solving). Term variable bindings associate program variables with their inferred or declared types, maintaining the mapping between identifiers in the source code and their type information. Judgments represent the core type checking and inference tasks that remain to be completed, encoding operations like subtyping checks, type synthesis, and type verification.

This tripartite structure allows the algorithm to defer complex decisions while systematically accumulating the information needed to make them correctly. By separating variable management from the actual type checking work, the algorithm can handle intricate dependencies and ensure that all constraints are resolved in the proper order.

### Type Variable Kinds

```rust
#![enum!("system-f-omega/src/worklist.rs", TyVarKind)]
```

Type variables in the worklist can have different statuses that reflect their role in the type checking process. Universal type variables represent ordinary type variables that arise from explicit quantifiers in the source code, such as the \\( \\alpha \\) in \\( \\forall\\alpha. \\ldots \\). These variables have fixed scope and represent abstract types that can be instantiated with concrete types during polymorphic function application. Existential type variables, denoted as \\( \\hat{\\alpha} \\), represent unknown types that need to be inferred through constraint solving. The algorithm generates these variables when it encounters expressions whose types are not immediately apparent and must be determined through unification and constraint propagation.

Solved existential variables represent the successful resolution of inference problems, taking the form \\( \\hat{\\alpha} = \\tau \\) where the unknown type \\( \\hat{\\alpha} \\) has been determined to be the concrete type \\( \\tau \\). Marker variables, denoted as \\( \\triangleright\\alpha \\), serve as scope markers that enable garbage collection of type variables when their scope is exited. This stratification enables precise control over variable scoping and solution propagation, ensuring that type variables are managed correctly throughout the inference process.

### Judgment Types

```rust
#![enum!("system-f-omega/src/worklist.rs", Judgment)]
```

Judgments represent the core type checking tasks that drive the DK algorithm forward. Subtyping judgments, written as \\( A \\leq B \\), verify that type \\( A \\) is a subtype of type \\( B \\), which is essential for handling the contravariant and covariant relationships that arise in function types and polymorphic instantiation. Inference judgments, denoted \\( e \\Rightarrow A \\), synthesize a type \\( A \\) for a given expression \\( e \\), allowing the algorithm to determine types from expressions when no expected type is available. Checking judgments, written as \\( e \\Leftarrow A \\), verify that a given expression \\( e \\) conforms to an expected type \\( A \\), which is often more efficient than synthesis when the target type is known.

Instantiation judgments handle the complex process of polymorphic type instantiation, managing the creation and resolution of existential variables that arise when applying polymorphic functions to arguments. Application judgments provide specialized handling for function application inference, dealing with the intricate constraint generation that occurs when the function type may not be immediately known. The algorithm processes these judgments by pattern matching on their structure and generating new worklist entries as needed, creating a systematic approach to constraint solving that ensures all type relationships are properly established.

## Bidirectional Type Checking

The DK algorithm employs bidirectional type checking, splitting inference into two complementary modes that work together to handle System Fω's complexity.

### Synthesis Mode (⇒)

```rust
#![function!("system-f-omega/src/worklist.rs", DKInference::solve_inference)]
```

Synthesis mode analyzes expressions to determine their types, working from the structure of expressions to produce type information. When encountering variables, the algorithm looks up their types in the current typing context, instantiating any polymorphic schemes as needed to produce concrete types for the current usage. Function applications require the algorithm to infer both the function and argument types, then unify them to ensure the application is well-typed. Type applications instantiate polymorphic types with concrete type arguments, requiring careful management of type variable substitution and scope.

Type annotations provide explicit guidance to the inference process, allowing programmers to specify expected types that the algorithm can use to constrain its search space. Synthesis mode produces not only a type but also any constraints that must hold for the typing to be valid, enabling the algorithm to handle complex interdependencies between different parts of the expression being analyzed.

### Checking Mode (⇐)

```rust
#![function!("system-f-omega/src/worklist.rs", DKInference::solve_checking)]
```

Checking mode verifies that expressions conform to expected types, working backwards from known type information to validate expression structure. For lambda expressions, the algorithm can immediately decompose the expected function type to extract parameter and return types, then check the lambda parameter against the expected parameter type and recursively check the body against the expected return type. When checking against polymorphic types, the algorithm introduces fresh type variables for the quantified variables and checks the expression against the instantiated type.

When direct checking strategies are not applicable, the algorithm falls back to a synthesis-plus-subtyping approach, where it first synthesizes a type for the expression and then verifies that this synthesized type is a subtype of the expected type. Checking mode is often more efficient than synthesis because it can make stronger assumptions about the expected type structure, allowing the algorithm to prune the search space and make more directed inferences.

## Existential Type Variables

Existential variables represent the unknown types that make type inference possible. They act as placeholders that get solved through unification and constraint propagation.

### Variable Generation

```rust
#![function!("system-f-omega/src/worklist.rs", Worklist::fresh_evar)]
```

Fresh existential variables are generated with unique names and added to the worklist. The algorithm ensures that each unknown type gets a distinct variable, preventing accidental unification.

### Constraint Generation

When the algorithm encounters expressions with unknown types, it follows a systematic constraint generation process. The algorithm creates fresh existential variables to represent the unknown types, ensuring each unknown gets a unique placeholder that can be tracked throughout the solving process. These existential variables are then related to known types through constraint generation, creating equations and inequalities that capture the type relationships implied by the program structure.

The generated constraints are added to the worklist for systematic resolution, allowing the algorithm to defer complex solving decisions until sufficient information is available. As constraints get resolved and existential variables receive concrete solutions, these solutions are propagated throughout the constraint system, potentially enabling the resolution of additional constraints in a cascading effect that gradually determines all unknown types.

### Solving Process

```rust
#![function!("system-f-omega/src/worklist.rs", DKInference::solve)]
```

Constraint solving proceeds through a systematic pattern matching process that determines which constraint solving rule applies to each judgment in the worklist. The algorithm examines the structure of constraints and applies appropriate decomposition strategies to break complex constraints into simpler, more manageable pieces. For instance, a constraint involving function types might be decomposed into separate constraints for the argument and return types.

Substitution plays a crucial role as solved variables are applied throughout the constraint system, replacing existential variables with their determined types wherever they appear. The occurs check prevents the creation of infinite types during unification by ensuring that a type variable does not appear within its own solution, maintaining the soundness of the type system. The solving process is guaranteed to terminate because System Fω has decidable type inference, meaning that every well-typed program will eventually reach a state where all constraints are resolved and all existential variables have concrete solutions.

## Subtyping and Polymorphic Instantiation

System Fω's subtyping relation captures the idea that more polymorphic types are subtypes of less polymorphic ones. This enables flexible use of polymorphic functions.

### Subtyping Rules

```rust
#![function!("system-f-omega/src/worklist.rs", DKInference::solve_subtype)]
```

The subtyping algorithm handles several fundamental relationships that govern type compatibility in System Fω. Reflexivity ensures that every type is considered a subtype of itself, providing the base case for subtyping derivations. Transitivity allows subtyping relationships to compose through intermediate types, so if \\( A \\leq B \\) and \\( B \\leq C \\), then \\( A \\leq C \\) holds automatically.

Function types exhibit the classic contravariant-covariant pattern, where a function type \\( A_1 \\to B_1 \\) is a subtype of \\( A_2 \\to B_2 \\) if \\( A_2 \\leq A_1 \\) (contravariant in arguments) and \\( B_1 \\leq B_2 \\) (covariant in results). Universal quantification follows the principle that \\( \\forall\\alpha. A \\leq B \\) holds if \\( A \\leq B \\) when \\( \\alpha \\) is instantiated with a fresh existential variable. Existential instantiation requires the algorithm to solve existential variables in ways that satisfy the subtyping constraints, often leading to the creation of additional constraints that must be resolved.

### Polymorphic Instantiation

```rust
#![function!("system-f-omega/src/worklist.rs", DKInference::instantiate_left)]
```

Instantiation handles the complex process of applying polymorphic functions by systematically managing the relationship between universal and existential quantification. The algorithm begins by identifying quantified variables in polymorphic types, analyzing the structure of \\( \\forall \\)-types to determine which type variables need instantiation. For each quantified variable, the algorithm generates fresh existential variables that will serve as placeholders for the concrete types to be determined through constraint solving.

The substitution phase replaces quantified variables with their corresponding existential variables throughout the type, effectively converting a polymorphic type scheme into a concrete type with unknown components. Additional constraints are added to ensure proper instantiation, capturing any relationships that must hold between the instantiated types and the context in which the polymorphic function is used. This systematic process enables the same polymorphic function to be used with different types in different contexts while maintaining type safety and ensuring that all instantiations are consistent with the function's type signature.

## Error Handling and Diagnostics

The DK algorithm provides precise error reporting by tracking the source of constraints and the reasoning that led to type checking failures.

```rust
#![enum!("system-f-omega/src/errors.rs", TypeError)]
```

The error system encompasses several categories of failures that can occur during type checking. Unification failures arise when the algorithm attempts to make two types equal but discovers they are fundamentally incompatible, such as trying to unify \\( \\text{Int} \\) with \\( \\text{Bool} \\to \\text{String} \\). Occurs check violations prevent the creation of infinite types by detecting when a type variable would appear within its own solution, such as attempting to solve \\( \\hat{\\alpha} = \\hat{\\alpha} \\to \\text{Int} \\).

Scope violations occur when type variables escape their intended scope, typically when an existential variable that should be local to a particular constraint solving context appears in the final type. Kind mismatches arise when type constructors are applied incorrectly, such as applying a type constructor that expects a higher-kinded argument to a concrete type. Each error includes location information and a description of the type checking rule that failed, enabling precise diagnostics that help programmers understand and fix type errors in their code.

When the algorithm succeeds, it finds the most general type for each expression. This means users get the maximum possible polymorphism without losing type safety.

## Worklist Optimizations

There are a couple of optimizations that can also be added to make this process more efficient.

```rust
#![function!("system-f-omega/src/worklist.rs", DKInference::solve_judgment)]
```

Smart scheduling of worklist entries improves performance through strategic constraint ordering. The algorithm prioritizes simple constraints that can be solved immediately, such as reflexive subtyping relationships or direct unification of concrete types, allowing these trivial cases to be resolved quickly and potentially simplify other constraints. Complex constraints that require extensive reasoning or depend on the resolution of other constraints are deferred until more information becomes available through the solving of simpler constraints.

Related constraints are batched together to reduce redundant work, enabling the algorithm to solve groups of interdependent constraints in a single pass rather than revisiting them multiple times. This scheduling strategy significantly reduces the overall computational cost of constraint solving by ensuring that each constraint is processed when it is most likely to be resolvable.

Constraints undergo systematic simplification before being added to the worklist to improve both performance and clarity. The algorithm eliminates trivial constraints such as \\( A \\leq A \\) that are always satisfied, preventing unnecessary work and reducing clutter in the constraint system. Related constraints are combined when possible to reduce the overall worklist size, such as merging multiple subtyping constraints involving the same types into more comprehensive relationships.

The simplification process also enables early detection of unsatisfiable constraints, allowing the algorithm to report type errors immediately rather than continuing with doomed constraint solving attempts. This preprocessing step ensures that the worklist contains only meaningful constraints that contribute to the type inference process, making the overall algorithm more efficient and the resulting error messages more precise.

## Putting It All Together

And there we have it - a complete System Fω type checker with bidirectional inference, higher-kinded types, and  constraint solving! The DK algorithm transforms what could be an intractable type inference problem into a systematic, decidable process that handles some of the most advanced features in type theory.

Let's see our type checker in action with a simple polymorphic example. First, create a test file:

```haskell
-- test_identity.hs
identity :: forall a. a -> a;
identity x = x;

test_int :: Int;
test_int = identity 42;
```

Now run the type checker:

```bash
$ cd system-f-omega
$ cargo run -- check test_identity.hs
```

The system produces output showing the successful type checking:

```
Parsed 4 declarations
Compiled to 0 type definitions and 2 term definitions
Checking identity : ∀a. a -> a ... ✓
Checking test_int : Int ... ✓
✓ Module 'test_identity.hs' typechecks successfully!
```

Perfect! Our type checker correctly verified that `identity` has the polymorphic type \\( \\forall a. a \\to a \\) and that `test_int` properly instantiates it with `Int`. The DK algorithm handled the universal quantification, constraint generation, and instantiation with all the sophistication of a production-quality type system.
